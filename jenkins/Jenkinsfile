pipeline {
  agent any

  environment {
    VENV = '.venv'
    MLFLOW_TRACKING_URI = 'http://mlflow:5000'
  }

  stages {
    stage('Checkout SCM') {
      steps { checkout scm }
    }

    stage('Setup Environment') {
      steps {
        sh """
          apt-get update && apt-get install -y python3 python3-venv python3-pip git nodejs npm
          python3 -m venv ${VENV}
          . ${VENV}/bin/activate
          pip install --upgrade pip
          pip install -r requirements.txt
        """
      }
    }

    stage('Security & Static Analysis') {
      steps {
        sh """
          mkdir -p reports
          . ${VENV}/bin/activate
          bandit -r src security -f json -o reports/bandit.json || true
          safety check --full-report || true
          pip-audit -r requirements.txt || true
        """
      }
    }

    stage('Train & Evaluate Model') {
      steps {
        sh """
          . ${VENV}/bin/activate
          python -m src.preprocessing
          python -m src.train
          python -m src.evaluate
        """
      }
    }

    stage('Robustness & MLSecOps') {
      steps {
        sh """
          . ${VENV}/bin/activate
          python -m src.adversarial_tests
          python -m src.poisoning_detection
          python -m src.drift_monitor
          python -m src.security_audit
        """
      }
    }

    stage('DVC Snapshot (add + commit + push)') {
      steps {
        sh """
          . ${VENV}/bin/activate
          cd dvc
          export PYTHONPATH=..
          dvc init --no-scm --force || true
          dvc repro
          # Outputs are already declared in dvc.yaml; just push tracked versions
          dvc push || true
        """
      }
    }

    stage('LLM Red Teaming (Garak & Promptfoo)') {
      steps {
        sh """
          . ${VENV}/bin/activate
          # Start LLM service in background
          python -m uvicorn src.llm_service:app --host 0.0.0.0 --port 8000 &
          LLM_PID=$!

          # Give the service time to start
          sleep 10

          mkdir -p reports

          # Garak red-teaming against the REST LLM service
          garak --model_type rest --model_name http://localhost:8000/chat --probes lmrc.Malwaregen,lmrc.SlurUsage,dan.Dan_6_0,promptinject.HijackHateHumans || true

          # Promptfoo behavioral tests
          npx promptfoo eval || true

          # Stop LLM service
          kill $LLM_PID || true
        """
      }
    }

    stage('Publish Model Card') {
      steps {
        sh """
          . ${VENV}/bin/activate
          python -m src.model_card
        """
      }
    }
  }

  post {
    always {
      archiveArtifacts artifacts: 'dvc/models/**, reports/**, model_card.md', fingerprint: true
    }
  }
}
